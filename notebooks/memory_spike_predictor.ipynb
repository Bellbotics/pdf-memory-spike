{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "497a1a79",
   "metadata": {},
   "source": [
    "\n",
    "# Memory Spike Predictor (PDF Processing)\n",
    "\n",
    "Predict **peak memory usage (MB)** for PDF processing jobs *before* they run, using a scikit-learn Pipeline.\n",
    "This notebook is structured so you can start with **synthetic data** and later **swap in real features**.\n",
    "\n",
    "**What you'll do:**\n",
    "1. Generate or load data (features → `peak_mem_mb` target)\n",
    "2. Train a `Pipeline(OneHotEncoder + GradientBoostingRegressor)`\n",
    "3. Evaluate with MAE, RMSE, R², and MAPE\n",
    "4. Visualize residuals and predicted vs actual\n",
    "5. Save the trained `pipeline.pkl`\n",
    "6. Use `predict(features)` for inference\n",
    "7. (Optional) Export to ONNX for JVM-native scoring\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9236bdb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys, platform\n",
    "print(\"Python:\", sys.version)\n",
    "print(\"Platform:\", platform.platform())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed13a34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, json, math, pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76cd2123",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "BASE_DIR = '/mnt/data/memory_spike_nb'\n",
    "PIPELINE_PATH = f\"/mnt/data/memory_spike_nb/pipeline.pkl\"\n",
    "METRICS_PATH = f\"/mnt/data/memory_spike_nb/metrics.json\"\n",
    "DATA_PATH = f\"/mnt/data/memory_spike_nb/sample_data.csv\"\n",
    "print(\"Artifacts will be saved under:\", BASE_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa93713",
   "metadata": {},
   "source": [
    "\n",
    "## 1) Data: synthesize or load\n",
    "\n",
    "Start with realistic synthetic data. Later, replace `synthesize_data` or add a `load_data(path)`\n",
    "function to bring in your real, sanitized dataset with the same schema.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8f18cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def synthesize_data(n=7000, seed=7):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    size_mb = rng.lognormal(mean=1.3, sigma=0.7, size=n)\n",
    "    pages = np.clip((rng.normal(30, 30, size=n)).round().astype(int), 1, 1500)\n",
    "    image_page_ratio = np.clip(rng.beta(2.2, 3.5, size=n), 0, 1)\n",
    "    dpi_estimate = np.clip((rng.normal(220, 80, size=n)).round().astype(int), 72, 600)\n",
    "    avg_image_size_kb = np.clip(rng.lognormal(mean=4.8, sigma=0.6, size=n), 20, 5000)\n",
    "    fonts_embedded_pct = np.clip(rng.normal(0.75, 0.18, size=n), 0, 1)\n",
    "    xref_error_count = rng.poisson(0.06, size=n)\n",
    "    ocr_required = rng.integers(0, 2, size=n)\n",
    "    producer = rng.choice(\n",
    "        [\"Adobe\",\"iText\",\"PDFBox\",\"Ghostscript\",\"Unknown\",\"Scanner\"],\n",
    "        size=n, p=[0.35,0.12,0.12,0.08,0.18,0.15]\n",
    "    )\n",
    "\n",
    "    latent = (\n",
    "        60\n",
    "        + 22 * np.log1p(size_mb)\n",
    "        + 0.08 * pages\n",
    "        + 900 * (image_page_ratio ** 1.7)\n",
    "        + 0.006 * np.clip(dpi_estimate - 150, 0, None) * pages**0.3\n",
    "        + 0.03 * avg_image_size_kb\n",
    "        + 240 * (1 - fonts_embedded_pct)\n",
    "        + 65 * np.tanh(xref_error_count)\n",
    "        + 120 * ocr_required * (image_page_ratio > 0.5)\n",
    "    )\n",
    "    producer_bias = {\"Adobe\": -40.0, \"iText\": -10.0, \"PDFBox\": 0.0, \"Ghostscript\": 20.0, \"Unknown\": 25.0, \"Scanner\": 70.0}\n",
    "    latent += np.vectorize(producer_bias.get)(producer)\n",
    "    noise = rng.normal(0, 60 + 0.6 * np.sqrt(np.maximum(latent, 1)), size=n)\n",
    "    peak_mem_mb = np.clip(latent + noise, 150, 12000)\n",
    "\n",
    "    df = pd.DataFrame(dict(\n",
    "        size_mb=np.round(size_mb,3),\n",
    "        pages=pages,\n",
    "        image_page_ratio=np.round(image_page_ratio,3),\n",
    "        dpi_estimate=dpi_estimate,\n",
    "        avg_image_size_kb=np.round(avg_image_size_kb,1),\n",
    "        fonts_embedded_pct=np.round(fonts_embedded_pct,3),\n",
    "        xref_error_count=xref_error_count,\n",
    "        ocr_required=ocr_required.astype(int),\n",
    "        producer=producer,\n",
    "        peak_mem_mb=np.round(peak_mem_mb,1),\n",
    "    ))\n",
    "    return df\n",
    "\n",
    "df = synthesize_data(n=7000, seed=7)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3b67fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.sample(500, random_state=1).to_csv(DATA_PATH, index=False)\n",
    "DATA_PATH\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361aa9bd",
   "metadata": {},
   "source": [
    "\n",
    "## 2) Train a scikit-learn Pipeline\n",
    "\n",
    "We use a `ColumnTransformer` to one-hot encode the categorical `producer` and keep numeric features as-is.\n",
    "Then we train a `GradientBoostingRegressor`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e367a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = df.drop(columns=[\"peak_mem_mb\"])\n",
    "y = df[\"peak_mem_mb\"].values\n",
    "\n",
    "num_features = [\"size_mb\",\"pages\",\"image_page_ratio\",\"dpi_estimate\",\n",
    "                \"avg_image_size_kb\",\"fonts_embedded_pct\",\"xref_error_count\",\"ocr_required\"]\n",
    "cat_features = [\"producer\"]\n",
    "\n",
    "pre = ColumnTransformer([\n",
    "    (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_features),\n",
    "    (\"num\", \"passthrough\", num_features),\n",
    "])\n",
    "\n",
    "pipe = Pipeline([\n",
    "    (\"pre\", pre),\n",
    "    (\"gbr\", GradientBoostingRegressor(random_state=0)),\n",
    "])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "pipe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41868a3c",
   "metadata": {},
   "source": [
    "\n",
    "## 3) Evaluate\n",
    "We report:\n",
    "- **MAE** (mean absolute error)\n",
    "- **RMSE** (root mean squared error)\n",
    "- **R²**\n",
    "- **MAPE** (percentage)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682f195e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_pred = pipe.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mape = float(np.mean(np.abs((y_test - y_pred) / np.maximum(y_test, 1e-6))) * 100.0)\n",
    "mae, rmse, r2, mape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb0000c",
   "metadata": {},
   "source": [
    "\n",
    "## 4) Visualizations\n",
    "Residuals vs predicted, and predicted vs actual (sorted).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36dedc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Residuals\n",
    "residuals = y_test - y_pred\n",
    "plt.figure()\n",
    "plt.scatter(y_pred, residuals, s=6)\n",
    "plt.axhline(0, linestyle=\"--\")\n",
    "plt.xlabel(\"Predicted peak MB\"); plt.ylabel(\"Residual (actual - pred)\")\n",
    "plt.title(\"Residuals vs Prediction\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6d6b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Predicted vs Actual\n",
    "idx = np.argsort(y_test)\n",
    "plt.figure()\n",
    "plt.plot(y_test[idx], label=\"Actual\")\n",
    "plt.plot(y_pred[idx], label=\"Predicted\")\n",
    "plt.xlabel(\"Sample (sorted by actual)\"); plt.ylabel(\"Peak Memory (MB)\")\n",
    "plt.title(\"Predicted vs Actual (test set)\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9773244",
   "metadata": {},
   "source": [
    "\n",
    "## 5) Save artifacts\n",
    "Export the trained `pipeline.pkl` and a `metrics.json` next to it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc76b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(PIPELINE_PATH, \"wb\") as f:\n",
    "    pickle.dump(pipe, f)\n",
    "\n",
    "metrics = {\"mae\": float(mae), \"rmse\": float(rmse), \"r2\": float(r2), \"mape_pct\": float(mape)}\n",
    "with open(METRICS_PATH, \"w\") as f:\n",
    "    json.dump(metrics, f, indent=2)\n",
    "\n",
    "PIPELINE_PATH, METRICS_PATH\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df441ce",
   "metadata": {},
   "source": [
    "\n",
    "## 6) Quick inference helper\n",
    "`predict(features: dict)` → returns predicted peak MB.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4bc4ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict(features: dict) -> float:\n",
    "    import pandas as pd, pickle\n",
    "    pipe_ = pickle.load(open(PIPELINE_PATH, \"rb\"))\n",
    "    return float(pipe_.predict(pd.DataFrame([features]))[0])\n",
    "\n",
    "# Example:\n",
    "predict({\n",
    "    \"size_mb\": 18.0,\n",
    "    \"pages\": 420,\n",
    "    \"image_page_ratio\": 0.92,\n",
    "    \"dpi_estimate\": 300,\n",
    "    \"avg_image_size_kb\": 850.0,\n",
    "    \"fonts_embedded_pct\": 0.35,\n",
    "    \"xref_error_count\": 2,\n",
    "    \"ocr_required\": 1,\n",
    "    \"producer\": \"Unknown\",\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af188386",
   "metadata": {},
   "source": [
    "\n",
    "## 7) (Optional) Export to ONNX\n",
    "If `skl2onnx` is available, export the pipeline for JVM-native inference with ONNX Runtime.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa458669",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "try:\n",
    "    from skl2onnx import to_onnx\n",
    "    from skl2onnx.common.data_types import FloatTensorType, StringTensorType, Int64TensorType\n",
    "\n",
    "    initial_types = [\n",
    "        (\"producer\", StringTensorType([None, 1])),\n",
    "        (\"size_mb\", FloatTensorType([None, 1])),\n",
    "        (\"pages\", Int64TensorType([None, 1])),\n",
    "        (\"image_page_ratio\", FloatTensorType([None, 1])),\n",
    "        (\"dpi_estimate\", Int64TensorType([None, 1])),\n",
    "        (\"avg_image_size_kb\", FloatTensorType([None, 1])),\n",
    "        (\"fonts_embedded_pct\", FloatTensorType([None, 1])),\n",
    "        (\"xref_error_count\", Int64TensorType([None, 1])),\n",
    "        (\"ocr_required\", Int64TensorType([None, 1])),\n",
    "    ]\n",
    "    onnx_model = to_onnx(pipe, initial_types=initial_types, target_opset=17)\n",
    "    ONNX_PATH = f\"{BASE_DIR}/pipeline.onnx\"\n",
    "    with open(ONNX_PATH, \"wb\") as f:\n",
    "        f.write(onnx_model.SerializeToString())\n",
    "    print(\"Exported:\", ONNX_PATH)\n",
    "except Exception as e:\n",
    "    print(\"ONNX export skipped or failed:\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2af447",
   "metadata": {},
   "source": [
    "\n",
    "## 8) Deployment notes\n",
    "- Load `pipeline.pkl` in a Python FastAPI sidecar and expose `/predict`\n",
    "- Or export to ONNX for in-process Java inference with ONNX Runtime\n",
    "- Keep a `thresholdMb` (e.g., 3500) in your Spring config to decide routing\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
